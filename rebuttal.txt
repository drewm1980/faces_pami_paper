We thank the reviewers for their constructive comments, and in particular
reviewer 1 for an extra in-depth review.  While we have philosophical
differences on several points, we feel the valuable constructive criticism has
helped us strengthen the paper considerably.  We will now respond to the
reviews in order.

Reviewer 1 makes several specific recommendations for reducing the length and
generally improving the presentation of the paper which we have heeded.  Please
refer to the change list for details. 

The core of Reviewer 1's objections to our paper is that face recognition in
the scenario we are targetting is solved, and thus, unworthy of further study.
Although it is impossible to prove that no practical face recognition system
exists for access control, to help address this we have added 
experimental comparison to demonstrate both
suboptimal performance of a state-of-the-art general recognition algorithm
on our data, and to maintain ballance, suboptimal performance of our algorithm
on the NIST-style data sets. MAY NEED TO BE TWEAKED PENDING EXPERIMENT RESULTS

We will now respond the objections enumerated by Reviewer 1:

1. Reviewer 1 asserts that in applications where users are cooperative, the
importance of handling occlusions is diminished.  While it is true that
cooperative users will not deliberately obscure their face, it is still
desirable to be robust to things like changes in eyewear and partial occclusion
from hats and scarves.  Furthermore, we have found that the use of the L1-norm
as a robust error function improves performance even when the test image does
not contain occlusions.  Any boundaries where the intensity changes in a
misaligned image can result in a large localised error component.  While
unoccluded faces are mostly smooth, sharp boundaries still occur where there
are cast shadows, especially at depth discontinuities such as the nostrils, the
sides of the nose, and partially open mouths.  

Reviewer 1 further compares face recognition to other biometrics such as iris
recognition and fingerprints, and claims that these technogolies are far more
reliable and convenient for access control applications.  We consider this is a
false dichotomy, as multi-modal systems are often used for high-stakes
applications.  Furthermore, it should not be under-emphasized that of all of
these biometrics, face recognition has the potential to be the least intrusive
to the user on a daily basis.  Ideally, face recognition will take place
automatically as you walk up to a door.

The reviewer further takes issue with the practicality of the acquisition
system.  Part of this may be due to a misunderstanding of the system.  The
"illumination pattern" is just a block of white pixels that moves around, and
the purpose is simply to ensure that we illuminate the subject from a wide
variety of illumination directions.  The geometry of the projectors is not
calibrated; they are simply hand positioned on a table so that the projected
images touch without much overlap.  A purpose-build illumination system could
largely do away with even this requirement.  

2. Reviewer 1's interest in face recognition for terrorist watchlist and law
enforcement applications is of limited relevance to the evaluation of this
article.  By claiming that "the field of face recognition has set itself the
goal of recognition with as few gallery images as possible", the reviewer is
conflating the constraints of one application of face recognition
(surveillance) with those of face recognition as a whole.  A huge part of the
message of our paper is that for application that allow it, we can and should
be gathering more and higher quality data at enrolment.  This idea is certainly
not new or even recent.  What ~is new is the confluence of: 1. The availability
of hardware to efficiently acquire such data (high intensity, high contrast
ratio DLP projectors) 2. Robust computational tools to use such data in a
principled fashion 3. Computer hardware fast enough to even contemplate using
entire images as features.

3. "It is conceivable that SRC is applicable to any feature as well - which
underscores the fact that it is simply a pattern classification toolbox - on
par with any found in a textbook on pattern recognition. What is it that makes
it special for face recognition?"

Most general pattern classification algorithms do not take into account the
physically motivated linear model that is central (though by no means unique)
to the problem of illumination variation.

4. Our goal is not to achieve the best recognition rates on the NIST family of
benchmarks (FERET, FRVT, FRGC, MBGC, GBU); rather it is to advance the state of
the art in face recognition given cooperative subjects.  The motivating
application of the NIST data sets is government law enforcement (originally for
enforcement of drug prohibition, and more recently shifting towards border
security).  This requires backwards compatibility with old image data, some of
which was gathered before computers were even in widespread use.  Due to these
historical reasons, none of these data sets contain multiple controlled
illuminations.  For example, FRGC contains at most two illuminations per person
in the gallery.  (Two studio lights were kept on, and a third light was
switched either on or off.) The techniques used to gather these data sets are a
poor choice for applications where users are cooperative, and are needlessly
restrictive.  While large public data sets are critical to the rigorous
comparison of recognition algorithms, their existence should not be used to
argue against the development of new data acquisition techniques and algorithms
appropriate for them.

5. We have added comparisons with XYZ systems that are unrelated to our framework.  
Please see the change list for details. UNFINISHED!!!

6. Although we claim to have a minimalist system that works in a realistic
access control setting, we do not claim to have solved all problems in face
recognition.  We will tone down the rhetoric in XYZ places. UNFINISHED!!

7. We will add further discussion contrasting the advantages and disadvantages of our
system vs. systems incorporating 3D models.

8. The issues of (mis)alignment and illumination variance are coupled in the
sense that if one problem is solved, the other problem becomes a lot easier.
WE HAVE CLARIFIED THIS IN THE PAPER.

9. If the data fits our model perfectly, at the correct alignment the only
corruptions are due to occlusions.  Until the images are perfectly aligned,
there is indeed a component of dense error caused by misalignment.  This dense
error component is indeed largest where the image gradient is high (or even
discontinuous), and the derivative of this error component is what drives the
algorithm to its solution.  We explicitly do blur and downsample the images to
mollify registration effects; multiscale alignment is a well-known technique,
and is not new to our paper.  HOSSEIN-PERHAPS YOU HAVE A REFERENCE WE COULD ADD
HERE?

10. Scattered light is light that has had its direction modified by interaction
with materials.  DREW-FIND A REFERENCE OR ARGUE FROM MAXWELL"S EQUATIONS AND
MATERIAL PROPERTIES

11. Rigorous justification of the choice of illuminations is a subject of 
continuing research.  Our current choice is motivated empirically by the
experiments described in the paper. 

12. To our knowlege, we are the first to use projectors for illumination in
face recognition applications.  Section 1A of the previous submission already
cites several other applications that use projectors as illumination sources.
WE HAVE ADDED THE REQUESTED REFERENCES TO THE CURRENT SUBMISSION.

13.  It is true that one or both stages of the algorithm could be substituted
with other techniques.  That said, the registration and recognition stages are
coherent in the sense that they are motivated by same modeling assumptions
(illumination model, sparse occlusion, etc.), they use the same robust penalty
on image error (the L1-norm), and they use the same numerical optimization
techniques (ALM).  While conceptual simplicity is a secondary concern in
algorithm design, starting with a minimalist foundation benefits both
practitioners as well as researchers.  Other researchers have already published
more complex extensions to our work. 

14. Since we perform alignment separately for each class in the gallery, the
computation for the alignment stage is linear in the size of the gallery.  The
variation in alignment across classes is indeed small, but still changes the
objective enough to affect recognition results.  Aligning to a generic face (or
a gallery based on "aligned" images of many people) is a good idea, and one we
have considered as well.  If nothing else, it could be used to improve
alignment initialization instead of using raw face detector output.  It may
also be useful to use the roughly aligned test image to quicky eliminate some
of the classes from further consideration.  Again, we have deliberately tried
to keep the algorithm as minimalist as possible for this publication.

15. The adaptation of the Lucas-Kanade algorithm to both the l1 norm cost
function and a linear illumination model is novel to our knowlege.  As
discussed earlier, we disagree with Reviewer 1's contention that data
acquisition is not a critical part of the face recognition problem.  We believe
we have demonstrated that using a well-though-out combination of existing ideas
(iterative image alignment, l1-error function, SRC, using projectors for
illumination), one can build a recognition that is conceptually simple, well
motivated, and competitive with state-of-the-art recognition systems for access
control scenarios.

Reviewer 2 raises 5 questions, which we will now address.  Since the
recognition optimization is convex and has no difficultly converging, we assume
that (i)-(iii) are asking about the iterative alignment.

(i) "How often an infinite loop is encountered, and how it is handled."

We place a hard limit on the maximal number of alignment iterations, so the
algorithm is guaranteed to terminate in finite time.  In practice, the
alignment algorithm tends to converge within 4-10 iterations for each
resolution of the multi-scale implementation.  We also place hard bounds on how
large the alignment can be, and terminate alignment early if these bounds are
reached.  In the cases where the alignment "slips off" the face, this is how
alignment terminates.  

(ii) "How often the starting point happens to be located in a wrong basin of
attraction, i.e. a wrong face. (If there is any way to know this.)"
(iii) "How often the solution gets drifted away into a wrong basin of
attraction. (If there is any way to know this.)"

Since we align the test image to the training users individually, we avoid the
potential problem of the test image converging to a local minimum corresponding
to a non-match face.

(iv) "What is the criteria or threshold for convergence? If the threshold is
stringent, the algorithms are likely to get stuck in infinite loops, and if the
threshold is liberal, premature convergence would occur. How are such
thresholds picked and how universal are they? Does every new dataset need its
own threshold?"

For the l1 minimizations we threshold the l1-norm of the difference between
successive values of the state (this includes the both the explicit
optimization variables and the lagrangle multipliers).  Similarly, for the
alignment iteration, we threshold the l1-norm of the update to the
transformation parameters.  We used the same set convergence thresholds for all
of the data sets we ran against.  In general, the l1-minimzations are
guaranteed to converge eventually, although convergence may be very slow if the
optimization parameters are chosen poorly.  ARVIND-DISCUSS ANY FURTHER RESULTS
ON CONVERGENCE YOU KNOW OF HERE.  

(v) "The problem, however, is that if we minimize a function one variable at
a time, we may actually end up increasing the function (L_{mu}(x,e,lambda_{k})) value." 

ARVIND, PLEASE CITE CONVERGENCE RESULTS FOR THIS

Reviewer 3 makes the following requests:

"I would have liked to see the experiment for the case S=1, without
impostors in the dataset, to judge the effect of the "Sparse
Concentration Index"

While we observe improved identification performance when using SCI, the main
purpose of SCI is imposter rejection.  
WE HAVE ADDED EXPERIMENTS TO THE PAPER DEMONSTRATING THE UTILITY OF THE SCI-BASED
RECOGNITION STAGE FOR BOTH IDENTIFICATION AND IMPOSTER REJECTION.

"I would also retitle the paper to include "robust measure"
instead of "sparse representation", as the L1 Cost is just a robust
cost, and the system would probably work as well or better with other
(even non-convex) robust cost functions."

We hope reviewer will find our supplemental justification for the (Sparse
Representation based) recognition convincing.  If so, the reviewer may
therefore also agree that the current title is indeed appropriate.

"It might be possible to streamline the introduction a bit more, such that it
clearly describes the algorithm before going into the details."

WE HAVE ATTEMPTED TO MAKE THE OVERALL STRUCTURE OF OUR SYSTEM CLEAR EARLIER IN THE
PAPER TO AVOID CONFUSION.

"Using and requiring several input images of a person asks for a
comment on the advantage or difference to a system that uses
a 3D representation of a face. Please comment on this!"

WE HAVE ENHANCED OUR DISCUSSION OF SYSTEMS THAT USE 3D MODELS IN THE PAPER.  PLEASE SEE THE
CHANGE LIST FOR DETAILS.
